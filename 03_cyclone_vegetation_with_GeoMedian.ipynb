{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab notebook\n",
    "from __future__ import print_function\n",
    "import datacube\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from datetime import date, timedelta\n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from datacube.storage import masking\n",
    "from datacube.storage.masking import mask_to_dict\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import rasterio\n",
    "from datacube_stats.statistics import GeoMedian\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "dc = datacube.Datacube(app='dc-show changes in annual mean NDVI values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User requirement: specify directory locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###User input: enter the directory location of input data.\n",
    "input_folder = '/g/data/w85/ext547/input_data/'\n",
    "\n",
    "###User input : enter the directory location of output data. Please enter again if the same as input_folder.\n",
    "output_folder = '/g/data/w85/ext547/output_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User requirement: specifiy location of interest and date of cyclone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###User input: enter area of interest\n",
    "lat_min = -20.385 #down\n",
    "lat_max = -20.326 #up\n",
    "lon_min = 148.916 #left\n",
    "lon_max = 148.984 #right\n",
    "\n",
    "##User input: enter the name of vegetation of interest, e.g. \"forest\" or \"banana crop\"\n",
    "vegetation_type = 'forest'\n",
    "\n",
    "###User input: enter start and end date of cyclone\n",
    "start_of_event= '2017-03-23'\n",
    "end_of_event= '2017-04-07'\n",
    "\n",
    "###User input:enter the name of cyclone\n",
    "cyclone_name =  'Yasi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datacube query is completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': ('2000-01-01', '2017-12-31'), 'x': (146.127, 146.186), 'y': (-17.925, -17.968), 'crs': 'EPSG:4326'}\n"
     ]
    }
   ],
   "source": [
    "#### DEFINE SPATIOTEMPORAL RANGE AND BANDS OF INTEREST\n",
    "#Use this to manually define an upper left/lower right coords\n",
    "#Either as polygon or as lat/lon range\n",
    "\n",
    "#Define temporal range\n",
    "start_of_epoch = '2000-01-01'\n",
    "#need a variable here that defines a rolling 'latest observation'\n",
    "end_of_epoch =  '2017-12-31'\n",
    "\n",
    "#Define wavelengths/bands of interest, remove this kwarg to retrieve all bands\n",
    "bands_of_interest = [#'blue',\n",
    "                     'green',\n",
    "                     'red', \n",
    "                     'nir',\n",
    "                     'swir1', \n",
    "                     #'swir2'\n",
    "                     ]\n",
    "\n",
    "#Define sensors of interest, # out sensors that aren't relevant for the time period\n",
    "sensors = [\n",
    "    'ls8', #May 2013 to present\n",
    "    'ls7', #1999 to present\n",
    "    'ls5' #1986 to present, full contintal coverage from 1987 onwards\n",
    "        ] \n",
    "\n",
    "\n",
    "query = {\n",
    "    'time': (start_of_epoch, end_of_epoch),\n",
    "}\n",
    "\n",
    "#your area of interest\n",
    "lat_min = -17.968 #-17.55 down\n",
    "lat_max = -17.925 #-17.50 up\n",
    "lon_min = 146.127 #145.95 left\n",
    "lon_max = 146.186 #146.00 right\n",
    "   \n",
    "query['x'] = (lon_min, lon_max)\n",
    "query['y'] = (lat_max, lat_min)\n",
    "query['crs'] = 'EPSG:4326'\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reformat event date format\n",
    "start_of_event=datetime.datetime.strptime(start_of_event,'%Y-%m-%d') #Convert to datetime\n",
    "end_of_event=datetime.datetime.strptime(end_of_event,'%Y-%m-%d') #Convert to datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data from Open Datacube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extracted data is first filtered using the criteria in \"mask_components\". \n",
    "The cloudiness of the scenes is then tested, and any scenes that do not meet the given \"cloud_free_threshold\" are discarded.\n",
    "Additionally, any pixel that is located within the sea are converted to \"nan\" values with the 'land_sea' command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create cloud mask and land/sea mask. This will define which pixel quality (PQ) artefacts are removed from the results.\n",
    "\n",
    "mask_components = {'cloud_acca':'no_cloud',\n",
    "'cloud_shadow_acca' :'no_cloud_shadow',\n",
    "'cloud_shadow_fmask' : 'no_cloud_shadow',\n",
    "'cloud_fmask' :'no_cloud',\n",
    "'blue_saturated' : False,\n",
    "'green_saturated' : False,\n",
    "'red_saturated' : False,\n",
    "'nir_saturated' : False,\n",
    "'swir1_saturated' : False,\n",
    "'swir2_saturated' : False,\n",
    "'contiguous':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ls8\n"
     ]
    }
   ],
   "source": [
    "#Retrieve the data for each Landsat sensor\n",
    "\n",
    "sensor_clean = {}\n",
    "cloud_free_threshold = 0.80  ###User modification: set cloud threshold. Default value is \"0.90\" or >90% image and <10% cloud cover\n",
    "                        ###Scenes will not be retrieved that have less than the cloud threshold worth of image.\n",
    "\n",
    "for sensor in sensors:\n",
    "    #Load the NBAR and corresponding PQ\n",
    "    sensor_nbar = dc.load(product= sensor+'_nbar_albers', group_by='solar_day', \n",
    "                          measurements = bands_of_interest,  **query)\n",
    "    sensor_pq = dc.load(product= sensor+'_pq_albers', group_by='solar_day', \n",
    "                        fuse_func=ga_pq_fuser, **query)\n",
    "    \n",
    "    #Retrieve the projection information before masking/sorting\n",
    "    crs = sensor_nbar.crs\n",
    "    crswkt = sensor_nbar.crs.wkt\n",
    "    affine = sensor_nbar.affine\n",
    "    \n",
    "    #Ensure there's PQ to go with the NBAR\n",
    "    sensor_nbar = sensor_nbar.sel(time = sensor_pq.time)\n",
    "    \n",
    "    #Apply the PQ masks to the NBAR\n",
    "    quality_mask = masking.make_mask(sensor_pq, **mask_components)\n",
    "    good_data = quality_mask.pixelquality.loc[start_of_epoch:end_of_epoch]\n",
    "    sensor_nbar2 = sensor_nbar.where(good_data)\n",
    "    \n",
    "    #Calculate the percentage cloud free for each scene\n",
    "    cloud_free = masking.make_mask(sensor_pq, cloud_acca='no_cloud', cloud_fmask='no_cloud', \n",
    "                                   contiguous=True).pixelquality\n",
    "    mostly_cloud_free = cloud_free.mean(dim=('x','y')) >= cloud_free_threshold\n",
    "        \n",
    "    #Discard data that does not meet the cloud_free_threshold\n",
    "    mostly_good = sensor_nbar2.where(mostly_cloud_free).dropna(dim='time', how='all')\n",
    "    mostly_good['product'] = ('time', numpy.repeat(sensor, mostly_good.time.size))    \n",
    "    sensor_clean[sensor] = mostly_good\n",
    "\n",
    "    print('loaded %s' % sensor) \n",
    "    \n",
    "\n",
    "print ('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the output\n",
    "\n",
    "sensor_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate (join) data from different sensors together and sort so that observations are sorted \n",
    "#by time rather than sensor\n",
    "\n",
    "nbar_clean = xr.concat(sensor_clean.values(), 'time')\n",
    "time_sorted = nbar_clean.time.argsort()\n",
    "nbar_clean = nbar_clean.isel(time=time_sorted)\n",
    "nbar_clean.attrs['crs'] = crs\n",
    "nbar_clean.attrs['affin|e'] = affine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate geomedian for all scenes prior to cyclone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove product data variable from array to enable GeoMedian code\n",
    "nbar_clean=nbar_clean.drop('product')\n",
    "\n",
    "#select all scenes that occur before the start of the cyclone\n",
    "nbar_gm= nbar_clean.sel(time=slice(start_of_epoch, start_of_event))\n",
    "\n",
    "#geomedian transform\n",
    "nbar_gm=GeoMedian().compute(nbar_gm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot imagery and NDVI for the geomedian of all data prior to the cyclone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare imagery\n",
    "rgb = nbar_gm.to_array(dim='color').sel(color=[\n",
    "    'swir1','nir', 'green']).transpose('y', 'x', 'color')\n",
    "fake_saturation = 6000.0\n",
    "rgb = rgb.astype('double')\n",
    "clipped_visible = rgb.where(rgb<fake_saturation).fillna(fake_saturation)\n",
    "max_val = clipped_visible.max(['y', 'x'])\n",
    "scaled = (clipped_visible / max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create small area image for the event of interest\n",
    "\n",
    "fig = plt.figure(figsize =(8,8)) #Edit size of plot ##User should format as required\n",
    "plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05) #Set border dimensions  ##User should format if required\n",
    "fig.patch.set_facecolor('white') #Make border white ##User should format if required\n",
    "fig.patch.set_alpha(0.99)#Make border white ##User should format if required\n",
    "plt.axis('off')#remove axis ##User should delete code if required\n",
    "plt.imshow(scaled, interpolation = 'nearest')\n",
    "\n",
    "plt.show() #Create plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate NDVI\n",
    "ndvi = ((nbar_gm.nir-nbar_gm.red)/(nbar_gm.nir+nbar_gm.red))\n",
    "ndvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This controls the colour maps used for plotting NDVI\n",
    "ndvi_cmap = mpl.colors.ListedColormap(['blue', '#ffcc66','#ffffcc' , '#ccff66' , '#2eb82e', '#009933' , '#006600'])\n",
    "ndvi_bounds = [-1, 0, 0.1, 0.25, 0.35, 0.5, 0.8, 1]\n",
    "ndvi_norm = mpl.colors.BoundaryNorm(ndvi_bounds, ndvi_cmap.N)\n",
    "ndvi.attrs['crs'] = crs\n",
    "ndvi.attrs['affine'] = affine\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.title('NDVI')\n",
    "plt.imshow(ndvi,interpolation = 'nearest', cmap = ndvi_cmap, norm = ndvi_norm)\n",
    "plt.axis('off')#remove axis ##User should delete code if required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot imagery and NDVI for timeslive after tropical cyclone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare imagery\n",
    "rgb2 = nbar_clean.sel(time =end_of_event, method = 'backfill').to_array(dim='color').sel(color=[\n",
    "    'swir1','nir', 'green']).transpose('y', 'x', 'color')\n",
    "fake_saturation = 6000.0\n",
    "rgb2 = rgb2.astype('double')\n",
    "clipped_visible2 = rgb2.where(rgb2<fake_saturation).fillna(fake_saturation)\n",
    "max_val2 = clipped_visible2.max(['y', 'x'])\n",
    "scaled2 = (clipped_visible2 / max_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create small area image for the event of interest\n",
    "\n",
    "fig = plt.figure(figsize =(8,8)) #Edit size of plot ##User should format as required\n",
    "plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05) #Set border dimensions  ##User should format if required\n",
    "fig.patch.set_facecolor('white') #Make border white ##User should format if required\n",
    "fig.patch.set_alpha(0.99)#Make border white ##User should format if required\n",
    "plt.axis('off')#remove axis ##User should delete code if required\n",
    "\n",
    "#Edit plot title ##User should format as required\n",
    "# plt.title('Gauge: '+gauge_of_interest +'   Date: '+str(time_slice_actual)[0:-9]  + \n",
    "#           '    Discharge: ' + discharge_title2+' $m^3$ $day^{-1}$' +\n",
    "#           '   Percentage exceedance: '+ str(perexc_title2) + '%', size=10) \n",
    "\n",
    "#Add marker to show location of stream gauge \n",
    "# plt.scatter(x = [sg_x], y = [sg_y], c= 'r', marker = 'o', s=150)\n",
    "plt.imshow(scaled2, interpolation = 'nearest')\n",
    "#            extent=[scaled.coords['x'].min(), scaled.coords['x'].max(), \n",
    "#                   scaled.coords['y'].min(), scaled.coords['y'].max()])\n",
    "plt.show() #Create plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_after_event = ((nbar_clean.nir-nbar_clean.red)/(nbar_clean.nir+nbar_clean.red))\n",
    "ndvi_after_event\n",
    "\n",
    "ndvi_of_interest2= ndvi_after_event.sel(time = end_of_event, method='backfill')\n",
    "ndvi_of_interest2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.title('NDVI after event')\n",
    "plt.axis('off')#remove axis ##User should delete code if required\n",
    "i=plt.imshow(ndvi_of_interest2,interpolation = 'nearest', cmap = ndvi_cmap, norm = ndvi_norm)\n",
    "fig.colorbar(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot change in NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndvi=(((ndvi-np.amin(ndvi))/(np.amax(ndvi)-np.amin(ndvi)))*100)\n",
    "# ndvi_of_interest2=(((ndvi_of_interest2-np.amin(ndvi_of_interest2))/(np.amax(ndvi_of_interest2)-np.amin(ndvi_of_interest2)))*100)\n",
    "\n",
    "ndvi_change= ndvi-ndvi_of_interest2\n",
    "ndvi_change=(((ndvi_change-np.amin(ndvi_change))/(np.amax(ndvi_change)-np.amin(ndvi_change)))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ndvi_change.plot(cmap = 'RdYlGn')\n",
    "plt.title('Change in mean NDVI between average and after event')\n",
    "plt.axis('off')#remove axis ##User should delete code if required\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
